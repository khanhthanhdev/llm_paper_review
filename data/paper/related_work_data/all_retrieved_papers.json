[
  {
    "paper_id": "167ad306d84cca2455bc50eb833454de9f2dcd02",
    "title": "Joint Language and Translation Modeling with Recurrent Neural Networks",
    "abstract": "We present a joint language and translation model based on a recurrent neural network which predicts target words based on an unbounded history of both source and target words. The weaker independence assumptions of this model result in a vastly larger search space compared to related feedforward-based language or translation models. We tackle this issue with a new lattice rescoring algorithm and demonstrate its effectiveness empirically. Our joint model builds on a well known recurrent neural network language model (Mikolov, 2012) augmented by a layer of additional inputs from the source language. We show competitive accuracy compared to the traditional channel model features. Our best results improve the output of a system trained on WMT 2012 French-English data by up to 1.5 BLEU, and by 1.1 BLEU on average across several test sets.",
    "publication_date": "2013-10-01",
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": "2013",
    "citation_count": 290,
    "authors": "Michael Auli, Michel Galley, Chris Quirk, G. Zweig",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
    "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "publication_date": "2014-09-01",
    "venue": "International Conference on Learning Representations",
    "year": "2014",
    "citation_count": 27707,
    "authors": "Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "6c2b28f9354f667cd5bd07afc0471d8334430da7",
    "title": "A Neural Probabilistic Language Model",
    "abstract": null,
    "publication_date": "2003-03-01",
    "venue": "Journal of machine learning research",
    "year": "2003",
    "citation_count": 7475,
    "authors": "Yoshua Bengio, R\u00e9jean Ducharme, Pascal Vincent, Christian Janvin",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "d0be39ee052d246ae99c082a565aba25b811be2d",
    "title": "Learning long-term dependencies with gradient descent is difficult",
    "abstract": null,
    "publication_date": "1994-03-01",
    "venue": "IEEE Trans. Neural Networks",
    "year": "1994",
    "citation_count": 8570,
    "authors": "Yoshua Bengio, Patrice Y. Simard, P. Frasconi",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "0b544dfe355a5070b60986319a3f51fb45d1348e",
    "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder\u2010 Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder\u2010Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "publication_date": "2014-06-03",
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": "2014",
    "citation_count": 23920,
    "authors": "Kyunghyun Cho, B. V. Merrienboer, \u00c7aglar G\u00fcl\u00e7ehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "398c296d0cc7f9d180f84969f8937e6d3a413796",
    "title": "Multi-column deep neural networks for image classification",
    "abstract": "Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible, wide and deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks.",
    "publication_date": "2012-02-13",
    "venue": "2012 IEEE Conference on Computer Vision and Pattern Recognition",
    "year": "2012",
    "citation_count": 3963,
    "authors": "D. Ciresan, U. Meier, J. Schmidhuber",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "6658bbf68995731b2083195054ff45b4eca38b3a",
    "title": "Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition",
    "abstract": "We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output. The deep belief network pre-training algorithm is a robust and often helpful way to initialize deep neural networks generatively that can aid in optimization and reduce generalization error. We illustrate the key components of our model, describe the procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects of various modeling choices on performance. Experiments on a challenging business search dataset demonstrate that CD-DNN-HMMs can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs, with an absolute sentence accuracy improvement of 5.8% and 9.2% (or relative error reduction of 16.0% and 23.2%) over the CD-GMM-HMMs trained using the minimum phone error rate (MPE) and maximum-likelihood (ML) criteria, respectively.",
    "publication_date": "2012-01-01",
    "venue": "IEEE Transactions on Audio, Speech, and Language Processing",
    "year": "2012",
    "citation_count": 3050,
    "authors": "George E. Dahl, Dong Yu, L. Deng, A. Acero",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "0894b06cff1cd0903574acaa7fcf071b144ae775",
    "title": "Fast and Robust Neural Network Joint Models for Statistical Machine Translation",
    "abstract": "Recent work has shown success in using neural network language models (NNLMs) as features in MT systems. Here, we present a novel formulation for a neural network joint model (NNJM), which augments the NNLM with a source context window. Our model is purely lexicalized and can be integrated into any MT decoder. We also present several variations of the NNJM which provide significant additive improvements.",
    "publication_date": "2014-06-01",
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": "2014",
    "citation_count": 574,
    "authors": "Jacob Devlin, Rabih Zbib, Zhongqiang Huang, Thomas Lamar, R. Schwartz, J. Makhoul",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "97cedf99252026f58e8154bc61d49cf885d42030",
    "title": "Edinburgh\u2019s Phrase-based Machine Translation Systems for WMT-14",
    "abstract": "This paper describes the University of Edinburgh\u2019s (UEDIN) phrase-based submissions to the translation and medical translation shared tasks of the 2014 Workshop on Statistical Machine Translation (WMT). We participated in all language pairs. We have improved upon our 2013 system by i) using generalized representations, specifically automatic word clusters for translations out of English, ii) using unsupervised character-based models to translate unknown words in RussianEnglish and Hindi-English pairs, iii) synthesizing Hindi data from closely-related Urdu data, and iv) building huge language on the common crawl corpus.",
    "publication_date": "2014-06-01",
    "venue": "WMT@ACL",
    "year": "2014",
    "citation_count": 56,
    "authors": "Nadir Durrani, B. Haddow, Philipp Koehn, Kenneth Heafield",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "6471fd1cbc081fb3b7b5b14d6ab9eaaba02b5c17",
    "title": "Generating Sequences With Recurrent Neural Networks",
    "abstract": "This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.",
    "publication_date": "2013-08-04",
    "venue": "arXiv.org",
    "year": "2013",
    "citation_count": 4094,
    "authors": "Alex Graves",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "261a056f8b21918e8616a429b2df6e1d5d33be41",
    "title": "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks",
    "abstract": null,
    "publication_date": "2006-06-25",
    "venue": "International Conference on Machine Learning",
    "year": "2006",
    "citation_count": 4570,
    "authors": "Alex Graves, Santiago Fern\u00e1ndez, Faustino J. Gomez, J\u00fcrgen Schmidhuber",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "c20ed3a1600122e6cf03b8ed74d3d2920ad0a8c6",
    "title": "Multilingual Distributed Representations without Word Alignment",
    "abstract": "Distributed representations of meaning are a natural way to encode covariance relationships between words and phrases in NLP. By overcoming data sparsity problems, as well as providing information about semantic relatedness which is not available in discrete representations, distributed representations have proven useful in many NLP tasks. Recent work has shown how compositional semantic representations can successfully be applied to a number of monolingual applications such as sentiment analysis. At the same time, there has been some initial success in work on learning shared word-level representations across languages. We combine these two approaches by proposing a method for learning distributed representations in a multilingual setup. Our model learns to assign similar embeddings to aligned sentences and dissimilar ones to sentence which are not aligned while not requiring word alignments. We show that our representations are semantically informative and apply them to a cross-lingual document classification task where we outperform the previous state of the art. Further, by employing parallel corpora of multiple language pairs we find that our model learns representations that capture semantic relationships across languages for which no parallel data was used.",
    "publication_date": "2013-12-20",
    "venue": "International Conference on Learning Representations",
    "year": "2013",
    "citation_count": 156,
    "authors": "Karl Moritz Hermann, Phil Blunsom",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "e33cbb25a8c7390aec6a398e36381f4f7770c283",
    "title": "Deep Neural Networks for Acoustic Modeling in Speech Recognition",
    "abstract": null,
    "publication_date": "2012-11-01",
    "venue": "",
    "year": "2012",
    "citation_count": 2492,
    "authors": "Geoffrey E. Hinton, L. Deng, Dong Yu, George E. Dahl, Abdel-rahman Mohamed, N. Jaitly, A. Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N. Sainath, Brian Kingsbury",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "2e5f2b57f4c476dd69dc22ccdf547e48f40a994c",
    "title": "Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies",
    "abstract": null,
    "publication_date": null,
    "venue": "",
    "year": "2001",
    "citation_count": 2003,
    "authors": "Sepp Hochreiter, Yoshua Bengio",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "2e9d221c206e9503ceb452302d68d10e293f2a10",
    "title": "Long Short-Term Memory",
    "abstract": null,
    "publication_date": "1997-11-01",
    "venue": "Neural Computation",
    "year": "1997",
    "citation_count": 94299,
    "authors": "Sepp Hochreiter, J. Schmidhuber",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "b158a006bebb619e2ea7bf0a22c27d45c5d19004",
    "title": "LSTM can Solve Hard Long Time Lag Problems",
    "abstract": null,
    "publication_date": "1996-12-03",
    "venue": "Neural Information Processing Systems",
    "year": "1996",
    "citation_count": 1001,
    "authors": "Sepp Hochreiter, J. Schmidhuber",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "944a1cfd79dbfb6fef460360a0765ba790f4027a",
    "title": "Recurrent Continuous Translation Models",
    "abstract": "We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is > 43% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.",
    "publication_date": "2013-10-01",
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": "2013",
    "citation_count": 1444,
    "authors": "Nal Kalchbrenner, Phil Blunsom",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
    "title": "ImageNet classification with deep convolutional neural networks",
    "abstract": null,
    "publication_date": "2012-12-03",
    "venue": "Communications of the ACM",
    "year": "2012",
    "citation_count": 122361,
    "authors": "A. Krizhevsky, I. Sutskever, Geoffrey E. Hinton",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "72e93aa6767ee683de7f001fa72f1314e40a8f35",
    "title": "Building high-level features using large scale unsupervised learning",
    "abstract": "We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a deep sparse autoencoder on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200\u00d7200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting from these learned features, we trained our network to recognize 22,000 object categories from ImageNet and achieve a leap of 70% relative improvement over the previous state-of-the-art.",
    "publication_date": "2011-12-29",
    "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
    "year": "2011",
    "citation_count": 2282,
    "authors": "Quoc V. Le, Marc'Aurelio Ranzato, R. Monga, M. Devin, G. Corrado, Kai Chen, J. Dean, A. Ng",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
    "title": "Gradient-based learning applied to document recognition",
    "abstract": null,
    "publication_date": null,
    "venue": "Proceedings of the IEEE",
    "year": "1998",
    "citation_count": 55976,
    "authors": "Yann LeCun, L. Bottou, Yoshua Bengio, P. Haffner",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "96364af2d208ea75ca3aeb71892d2f7ce7326b55",
    "title": "Statistical Language Models Based on Neural Networks",
    "abstract": null,
    "publication_date": null,
    "venue": "",
    "year": "2012",
    "citation_count": 640,
    "authors": "Vysok\u00e9 U\u010den\u00ed, Technick\u00e9 V Brn\u011b, Grafiky A Multim\u00e9di\u00ed, Diserta\u010dn\u00ed Pr\u00e1ce",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "9819b600a828a57e1cde047bbe710d3446b30da5",
    "title": "Recurrent neural network based language model",
    "abstract": null,
    "publication_date": null,
    "venue": "Interspeech",
    "year": "2010",
    "citation_count": 5947,
    "authors": "Tomas Mikolov, M. Karafi\u00e1t, L. Burget, J. \u010cernock\u00fd, S. Khudanpur",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "d7da009f457917aa381619facfa5ffae9329a6e9",
    "title": "Bleu: a Method for Automatic Evaluation of Machine Translation",
    "abstract": "Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.",
    "publication_date": "2002-07-06",
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": "2002",
    "citation_count": 29515,
    "authors": "K. Papineni, Salim Roukos, T. Ward, Wei-Jing Zhu",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "84069287da0a6b488b8c933f3cb5be759cb6237e",
    "title": "On the difficulty of training recurrent neural networks",
    "abstract": "There are two widely known issues with properly training recurrent neural networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.",
    "publication_date": "2012-11-21",
    "venue": "International Conference on Machine Learning",
    "year": "2012",
    "citation_count": 5472,
    "authors": "Razvan Pascanu, Tomas Mikolov, Yoshua Bengio",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "6122c95ac6475e965bf4e120f7a588d29bb00ecc",
    "title": "Overcoming the Curse of Sentence Length for Neural Machine Translation using Automatic Segmentation",
    "abstract": "The authors of (Cho et al., 2014a) have shown that the recently introduced neural network translation systems suffer from a significant drop in translation quality when translating long sentences, unlike existing phrase-based translation systems. In this paper, we propose a way to address this issue by automatically segmenting an input sentence into phrases that can be easily translated by the neural network translation model. Once each segment has been independently translated by the neural machine translation model, the translated clauses are concatenated to form a final translation. Empirical results show a significant improvement in translation quality for long sentences.",
    "publication_date": "2014-09-03",
    "venue": "SSST@EMNLP",
    "year": "2014",
    "citation_count": 83,
    "authors": "Jean Pouget-Abadie, Dzmitry Bahdanau, B. V. Merrienboer, Kyunghyun Cho, Yoshua Bengio",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "06342ba4480526574a8d864a3c3c1719450e2463",
    "title": "On Small Depth Threshold Circuits",
    "abstract": null,
    "publication_date": "1992-07-08",
    "venue": "Scandinavian Workshop on Algorithm Theory",
    "year": "1992",
    "citation_count": 56,
    "authors": "A. Razborov",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "052b1d8ce63b07fec3de9dbb583772d860b7c769",
    "title": "Learning representations by back-propagating errors",
    "abstract": null,
    "publication_date": "1986-10-01",
    "venue": "Nature",
    "year": "1986",
    "citation_count": 28583,
    "authors": "D. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "f9a1b3850dfd837793743565a8af95973d395a4e",
    "title": "LSTM Neural Networks for Language Modeling",
    "abstract": null,
    "publication_date": null,
    "venue": "Interspeech",
    "year": "2012",
    "citation_count": 1947,
    "authors": "M. Sundermeyer, Ralf Schl\u00fcter, H. Ney",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "1a3d22599028a05669e884f3eaf19a342e190a87",
    "title": "Backpropagation Through Time: What It Does and How to Do It",
    "abstract": null,
    "publication_date": "1990-10-01",
    "venue": "Proceedings of the IEEE",
    "year": "1990",
    "citation_count": 5052,
    "authors": "P. Werbos",
    "novel": null,
    "cited_paper": true
  },
  {
    "paper_id": "43428880d75b3a14257c3ee9bda054e61eb869c0",
    "title": "Convolutional Sequence to Sequence Learning",
    "abstract": "The prevalent approach to sequence to sequence learning maps an input sequence to a variable length output sequence via recurrent neural networks. We introduce an architecture based entirely on convolutional neural networks. Compared to recurrent models, computations over all elements can be fully parallelized during training and optimization is easier since the number of non-linearities is fixed and independent of the input length. Our use of gated linear units eases gradient propagation and we equip each decoder layer with a separate attention module. We outperform the accuracy of the deep LSTM setup of Wu et al. (2016) on both WMT'14 English-German and WMT'14 English-French translation at an order of magnitude faster speed, both on GPU and CPU.",
    "publication_date": "2017-05-08",
    "venue": "",
    "year": 2017,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "1bfa62ddfa3f6691e0e40c06f8ead594b6449cfa",
    "title": "OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework",
    "abstract": "In this work, we pursue a unified paradigm for multimodal pretraining to break the scaffolds of complex task/modality-specific customization. We propose OFA, a Task-Agnostic and Modality-Agnostic framework that supports Task Comprehensiveness. OFA unifies a diverse set of cross-modal and unimodal tasks, including image generation, visual grounding, image captioning, image classification, language modeling, etc., in a simple sequence-to-sequence learning framework. OFA follows the instruction-based learning in both pretraining and finetuning stages, requiring no extra task-specific layers for downstream tasks. In comparison with the recent state-of-the-art vision&language models that rely on extremely large cross-modal datasets, OFA is pretrained on only 20M publicly available image-text pairs. Despite its simplicity and relatively small-scale training data, OFA achieves new SOTAs in a series of cross-modal tasks while attaining highly competitive performances on uni-modal tasks. Our further analysis indicates that OFA can also effectively transfer to unseen tasks and unseen domains. Our code and models are publicly available at https://github.com/OFA-Sys/OFA.",
    "publication_date": "2022-02-07",
    "venue": "",
    "year": 2022,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "cbeee2f7f03acb575f250e7b1857ceb775db98ec",
    "title": "SeqTrack: Sequence to Sequence Learning for Visual Object Tracking",
    "abstract": "In this paper, we present a new sequence-to-sequence learning framework for visual tracking, dubbed SeqTrack. It casts visual tracking as a sequence generation problem, which predicts object bounding boxes in an autoregressive fashion. This is different from prior Siamese trackers and transformer trackers, which rely on designing complicated head networks, such as classification and regression heads. SeqTrack only adopts a simple encoder-decoder transformer architecture. The encoder extracts visual features with a bidirectional transformer, while the decoder generates a sequence of bounding box values autoregressively with a causal transformer. The loss function is a plain cross-entropy. Such a sequence learning paradigm not only simplifies tracking framework, but also achieves competitive performance on benchmarks. For instance, SeqTrack gets 72.5% AUC on LaSOT, establishing a new state-of-the-art performance. Code and models are available at https://github.com/microsoft/VideoX.",
    "publication_date": "2023-06-01",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "ecce44df1956db4ec486539c6543345344809958",
    "title": "Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework",
    "abstract": null,
    "publication_date": null,
    "venue": "",
    "year": 2022,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "84f3290630be8dff726ca43195ed6c82bb65d0d9",
    "title": "Self-Training Multi-Sequence Learning with Transformer for Weakly Supervised Video Anomaly Detection",
    "abstract": "Weakly supervised Video Anomaly Detection (VAD) using Multi-Instance Learning (MIL) is usually based on the fact that the anomaly score of an abnormal snippet is higher than that of a normal snippet. In the beginning of training, due to the limited accuracy of the model, it is easy to select the wrong abnormal snippet. In order to reduce the probability of selection errors, we first propose a Multi-Sequence Learning (MSL) method and a hinge-based MSL ranking loss that uses a sequence composed of multiple snippets as an optimization unit. We then design a Transformer-based MSL network to learn both video-level anomaly probability and snippet-level anomaly scores. In the inference stage, we propose to use the video-level anomaly probability to suppress the fluctuation of snippet-level anomaly scores. Finally, since VAD needs to predict the snippet-level anomaly scores, by gradually reducing the length of selected sequence, we propose a self-training strategy to gradually refine the anomaly scores. Experimental results show that our method achieves significant improvements on ShanghaiTech, UCF-Crime, and XD-Violence.",
    "publication_date": "2022-06-28",
    "venue": "",
    "year": 2022,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "a6336fa1bcdeb7c84d2c4189728f0c1b2b7d0883",
    "title": "A Critical Review of Recurrent Neural Networks for Sequence Learning",
    "abstract": "Countless learning tasks require dealing with sequential data. Image captioning, speech synthesis, and music generation all require that a model produce outputs that are sequences. In other domains, such as time series prediction, video analysis, and musical information retrieval, a model must learn from inputs that are sequences. Interactive tasks, such as translating natural language, engaging in dialogue, and controlling a robot, often demand both capabilities. Recurrent neural networks (RNNs) are connectionist models that capture the dynamics of sequences via cycles in the network of nodes. Unlike standard feedforward neural networks, recurrent networks retain a state that can represent information from an arbitrarily long context window. Although recurrent neural networks have traditionally been dicult to train, and often contain millions of parameters, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful large-scale learning with them. In recent years, systems based on long short-term memory (LSTM) and bidirectional (BRNN) architectures have demonstrated ground-breaking performance on tasks as varied as image captioning, language translation, and handwriting recognition. In this survey, we review and synthesize the research that over the past three decades rst yielded and then made practical these powerful learning models. When appropriate, we reconcile conicting notation and nomenclature. Our goal is to provide a selfcontained explication of the state of the art together with a historical perspective and references to primary research.",
    "publication_date": "2015-05-29",
    "venue": "",
    "year": 2015,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "02534853626c18c9a097c2712f1ddf3613257d35",
    "title": "Incorporating Copying Mechanism in Sequence-to-Sequence Learning",
    "abstract": "We address an important problem in sequence-to-sequence (Seq2Seq) learning referred to as copying, in which certain segments in the input sequence are selectively replicated in the output sequence. A similar phenomenon is observable in human language communication. For example, humans tend to repeat entity names or even long phrases in conversation. The challenge with regard to copying in Seq2Seq is that new machinery is needed to decide when to perform the operation. In this paper, we incorporate copying into neural network-based Seq2Seq learning and propose a new model called CopyNet with encoder-decoder structure. CopyNet can nicely integrate the regular way of word generation in the decoder with the new copying mechanism which can choose sub-sequences in the input sequence and put them at proper places in the output sequence. Our empirical study on both synthetic data sets and real world data sets demonstrates the efficacy of CopyNet. For example, CopyNet can outperform regular RNN-based model with remarkable margins on text summarization tasks.",
    "publication_date": "2016-03-21",
    "venue": "",
    "year": 2016,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "0289d774bd0dc8025005110973d5b8e6439197d8",
    "title": "Temporal Spike Sequence Learning via Backpropagation for Deep Spiking Neural Networks",
    "abstract": "Spiking neural networks (SNNs) are well suited for spatio-temporal learning and implementations on energy-efficient event-driven neuromorphic processors. However, existing SNN error backpropagation (BP) methods lack proper handling of spiking discontinuities and suffer from low performance compared with the BP methods for traditional artificial neural networks. In addition, a large number of time steps are typically required to achieve decent performance, leading to high latency and rendering spike-based computation unscalable to deep architectures. We present a novel Temporal Spike Sequence Learning Backpropagation (TSSL-BP) method for training deep SNNs, which breaks down error backpropagation across two types of inter-neuron and intra-neuron dependencies and leads to improved temporal learning precision. It captures inter-neuron dependencies through presynaptic firing times by considering the all-or-none characteristics of firing activities and captures intra-neuron dependencies by handling the internal evolution of each neuronal state in time. TSSL-BP efficiently trains deep SNNs within a much shortened temporal window of a few steps while improving the accuracy for various image classification datasets including CIFAR10.",
    "publication_date": "2020-02-24",
    "venue": "",
    "year": 2020,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "4aa9f5150b46320f534de4747a2dd0cd7f3fe292",
    "title": "Semi-supervised Sequence Learning",
    "abstract": "We present two approaches to use unlabeled data to improve Sequence Learning with recurrent networks. The first approach is to predict what comes next in a sequence, which is a language model in NLP. The second approach is to use a sequence autoencoder, which reads the input sequence into a vector and predicts the input sequence again. These two algorithms can be used as a \"pretraining\" algorithm for a later supervised sequence learning algorithm. In other words, the parameters obtained from the pretraining step can then be used as a starting point for other supervised training models. In our experiments, we find that long short term memory recurrent networks after pretrained with the two approaches become more stable to train and generalize better. With pretraining, we were able to achieve strong performance in many classification tasks, such as text classification with IMDB, DBpedia or image recognition in CIFAR-10.",
    "publication_date": "2015-11-04",
    "venue": "",
    "year": 2015,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500",
    "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling",
    "abstract": "We introduce a framework that abstracts Reinforcement Learning (RL) as a sequence modeling problem. This allows us to draw upon the simplicity and scalability of the Transformer architecture, and associated advances in language modeling such as GPT-x and BERT. In particular, we present Decision Transformer, an architecture that casts the problem of RL as conditional sequence modeling. Unlike prior approaches to RL that fit value functions or compute policy gradients, Decision Transformer simply outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired return (reward), past states, and actions, our Decision Transformer model can generate future actions that achieve the desired return. Despite its simplicity, Decision Transformer matches or exceeds the performance of state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.",
    "publication_date": "2021-06-02",
    "venue": "",
    "year": 2021,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "cfe190d5cc9a7d63eb1962a912f9655540de9a94",
    "title": "A Rainfall\u2010Runoff Model With LSTM\u2010Based Sequence\u2010to\u2010Sequence Learning",
    "abstract": "Rainfall\u2010runoff modeling is a complex nonlinear time series problem. While there is still room for improvement, researchers have been developing physical and machine learning models for decades to predict runoff using rainfall data sets. With the advancement of computational hardware resources and algorithms, deep learning methods such as the long short\u2010term memory (LSTM) model and sequence\u2010to\u2010sequence (seq2seq) modeling have shown a good deal of promise in dealing with time series problems by considering long\u2010term dependencies and multiple outputs. This study presents an application of a prediction model based on LSTM and the seq2seq structure to estimate hourly rainfall\u2010runoff. Focusing on two Midwestern watersheds, namely, Clear Creek and Upper Wapsipinicon River in Iowa, these models were used to predict hourly runoff for a 24\u2010hr period using rainfall observation, rainfall forecast, runoff observation, and empirical monthly evapotranspiration data from all stations in these two watersheds. The models were evaluated using the Nash\u2010Sutcliffe efficiency coefficient, the correlation coefficient, statistical bias, and the normalized root\u2010mean\u2010square error. The results show that the LSTM\u2010seq2seq model outperforms linear regression, Lasso regression, Ridge regression, support vector regression, Gaussian processes regression, and LSTM in all stations from these two watersheds. The LSTM\u2010seq2seq model shows sufficient predictive power and could be used to improve forecast accuracy in short\u2010term flood forecast applications. In addition, the seq2seq method was demonstrated to be an effective method for time series predictions in hydrology.",
    "publication_date": "2020-01-01",
    "venue": "",
    "year": 2020,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "59cc0871534a20ac98db0663539c6675ab63566f",
    "title": "SequenceR: Sequence-to-Sequence Learning for End-to-End Program Repair",
    "abstract": "This paper presents a novel end-to-end approach to program repair based on sequence-to-sequence learning. We devise, implement, and evaluate a technique, called SequenceR, for fixing bugs based on sequence-to-sequence learning on source code. This approach uses the copy mechanism to overcome the unlimited vocabulary problem that occurs with big code. Our system is data-driven; we train it on 35,578 samples, carefully curated from commits to open-source repositories. We evaluate SequenceR on 4,711 independent real bug fixes, as well on the Defects4J benchmark used in program repair research. SequenceR is able to perfectly predict the fixed line for 950/4,711 testing samples, and find correct patches for 14 bugs in Defects4J benchmark. SequenceR captures a wide range of repair operators without any domain-specific top-down design.",
    "publication_date": "2018-12-24",
    "venue": "",
    "year": 2018,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "6ff65ec0da19d7e9cc0745a3e90bce3a07fe83d5",
    "title": "IDP-Seq2Seq: identification of intrinsically disordered regions based on sequence to sequence learning",
    "abstract": "MOTIVATION\nRelated to many important biological functions, intrinsically disordered regions (IDRs) are widely distributed in proteins. Accurate prediction of intrinsically disordered regions is critical for the protein structure and function analysis. However, the existing computational methods construct the predictive models solely in the sequence space, failing to convert the sequence space into the \"semantic space\" to reflect the structure characteristics of proteins. Furthermore, although the length-dependent predictors showed promising results, new fusion strategies should be explored to improve their predictive performance and the generalization.\n\n\nRESULTS\nIn this study, we applied the Sequence to Sequence Learning (Seq2Seq) derived from natural language processing (NLP) to map protein sequences to \"semantic space\" to reflect the structure patterns with the help of predicted Residue-Residue Contacts (CCMs) and other sequence-based features. Furthermore, the Attention mechanism was employed to capture the global associations between all residue pairs in the proteins. Three length-dependent predictors were constructed: IDP-Seq2Seq-L for long disordered region prediction, IDP-Seq2Seq-S for short disordered region prediction, and IDP-Seq2Seq-G for both long and short disordered region prediction. Finally, these three predictors were fused into one predictor called IDP-Seq2Seq to improve the discriminative power and generalization. Experimental results on four independent test datasets and the CASP test dataset showed that IDP-Seq2Seq is insensitive with the ratios of long and short disordered regions and outperforms other competing methods.\n\n\nAVAILABILITY\nFor the convenience of most experimental scientists, a user-friendly and publicly accessible web-server for the powerful new predictor has been established at http://bliulab.net/IDP-Seq2Seq/. It is anticipated that IDP-Seq2Seq will become a very useful tool for identification of intrinsically disordered regions.\n\n\nSUPPLEMENTARY INFORMATION\nSupplementary data are available at Bioinformatics online.",
    "publication_date": "2020-07-23",
    "venue": "",
    "year": 2020,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "bbe512197b5b9ecf1691dd2ecfd35be28cdada27",
    "title": "Dual Attention-Based Encoder\u2013Decoder: A Customized Sequence-to-Sequence Learning for Soft Sensor Development",
    "abstract": "Soft sensor techniques have been applied to predict the hard-to-measure quality variables based on the easy-to-measure process variables in industry scenarios. Since the products are usually produced with prearranged processing orders, the sequential dependence among different variables can be important for the process modeling. To use this property, a dual attention-based encoder\u2013decoder is developed in this article, which presents a customized sequence-to-sequence learning for soft sensor. We reveal that different quality variables in the same process are sequentially dependent on each other and the process variables are natural time sequences. Hence, the encoder\u2013decoder is constructed to explicitly exploit the sequential information of both the input, that is, the process variables, and the output, that is, the quality variables. The encoder and decoder modules are specified as the long short-term memory network. In addition, since different process variables and time points impose different effects on the quality variables, a dual attention mechanism is embedded into the encoder\u2013decoder to concurrently search the quality-related process variables and time points for a fine-grained quality prediction. Comprehensive experiments are performed based on a real cigarette production process and a benchmark multiphase flow process, which illustrate the effectiveness of the proposed encoder\u2013decoder and its sequence to sequence learning for soft sensor.",
    "publication_date": "2020-08-24",
    "venue": "",
    "year": 2020,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "b7b97fff93bcd32aa2d1c9bc1acc3827bb3d4347",
    "title": "Sequence-to-Sequence Learning with Latent Neural Grammars",
    "abstract": "Sequence-to-sequence learning with neural networks has become the de facto standard for sequence prediction tasks. This approach typically models the local distribution over the next word with a powerful neural network that can condition on arbitrary context. While flexible and performant, these models often require large datasets for training and can fail spectacularly on benchmarks designed to test for compositional generalization. This work explores an alternative, hierarchical approach to sequence-to-sequence learning with quasi-synchronous grammars, where each node in the target tree is transduced by a node in the source tree. Both the source and target trees are treated as latent and induced during training. We develop a neural parameterization of the grammar which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering. We apply this latent neural grammar to various domains -- a diagnostic language navigation task designed to test for compositional generalization (SCAN), style transfer, and small-scale machine translation -- and find that it performs respectably compared to standard baselines.",
    "publication_date": "2021-09-02",
    "venue": "",
    "year": 2021,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "2c99bb725653385222b5d953605d1f7625628f73",
    "title": "Automated Depression Detection Using Deep Representation and Sequence Learning with EEG Signals",
    "abstract": null,
    "publication_date": "2019-05-28",
    "venue": "",
    "year": 2019,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "9c567e7096881e4bd086d51946bd8a6f8bbc8aab",
    "title": "A critical re-evaluation of fMRI signatures of motor sequence learning",
    "abstract": "Despite numerous studies, there is little agreement about what brain changes accompany motor sequence learning, partly because of a general publication bias that favors novel results. We therefore decided to systematically reinvestigate proposed functional magnetic resonance imaging correlates of motor learning in a preregistered longitudinal study with four scanning sessions over 5 weeks of training. Activation decreased more for trained than untrained sequences in premotor and parietal areas, without any evidence of learning-related activation increases. Premotor and parietal regions also exhibited changes in the fine-grained, sequence-specific activation patterns early in learning, which stabilized later. No changes were observed in the primary motor cortex (M1). Overall, our study provides evidence that human motor sequence learning occurs outside of M1. Furthermore, it shows that we cannot expect to find activity increases as an indicator for learning, making subtle changes in activity patterns across weeks the most promising fMRI correlate of training-induced plasticity.",
    "publication_date": "2020-01-09",
    "venue": "",
    "year": 2020,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "f11198dc277af1c5547ab3ae8d562fc8c16a7c70",
    "title": "Graph-to-Sequence Learning using Gated Graph Neural Networks",
    "abstract": "Many NLP applications can be framed as a graph-to-sequence learning problem. Previous work proposing neural architectures on graph-to-sequence obtained promising results compared to grammar-based approaches but still rely on linearisation heuristics and/or standard recurrent networks to achieve the best performance. In this work propose a new model that encodes the full structural information contained in the graph. Our architecture couples the recently proposed Gated Graph Neural Networks with an input transformation that allows nodes and edges to have their own hidden representations, while tackling the parameter explosion problem present in previous work. Experimental results shows that our model outperforms strong baselines in generation from AMR graphs and syntax-based neural machine translation.",
    "publication_date": "2018-06-26",
    "venue": "",
    "year": 2018,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "d58438041e8d645a3e531325d4f0aed3dbe41920",
    "title": "Densely Connected Graph Convolutional Networks for Graph-to-Sequence Learning",
    "abstract": "We focus on graph-to-sequence learning, which can be framed as transducing graph structures to sequences for text generation. To capture structural information associated with graphs, we investigate the problem of encoding graphs using graph convolutional networks (GCNs). Unlike various existing approaches where shallow architectures were used for capturing local structural information only, we introduce a dense connection strategy, proposing a novel Densely Connected Graph Convolutional Network (DCGCN). Such a deep architecture is able to integrate both local and non-local features to learn a better structural representation of a graph. Our model outperforms the state-of-the-art neural models significantly on AMR-to-text generation and syntax-based neural machine translation.",
    "publication_date": "2019-06-01",
    "venue": "",
    "year": 2019,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "dc889d3f6d199ae67576a209c6ab0188abbd3e27",
    "title": "Remaining Useful Life Prediction Using a Novel Feature-Attention-Based End-to-End Approach",
    "abstract": "Deep learning plays an increasingly important role in industrial applications, such as the remaining useful life (RUL) prediction of machines. However, when dealing with multifeature data, most deep learning approaches do not have effective mechanisms to weigh the input features adaptively. In this article, a novel feature-attention-based end-to-end approach is proposed for RUL prediction. First, the proposed feature-attention mechanism is directly applied to the input data, which gives greater attention weights to more important features dynamically in the training process. This helps the model focus more on those critical inputs, and the prediction performance is therefore improved. Next, bidirectional gated recurrent units (BGRU) are used to extract long-term dependencies from the weighted input data, and convolutional neural networks are employed to capture local features from the output sequences of BGRU. Finally, fully connected networks are used to learn the above-mentioned abstract representations to predict the RUL. The proposed approach is validated in a case study of turbofan engines. The experimental results demonstrate that the proposed approach outperforms other latest existing approaches.",
    "publication_date": "2021-02-01",
    "venue": "",
    "year": 2021,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "4b49329c48e78a0acb9c0e79e9a9df976088e680",
    "title": "BottleNet++: An End-to-End Approach for Feature Compression in Device-Edge Co-Inference Systems",
    "abstract": "The emergence of various intelligent mobile applications demands the deployment of powerful deep learning models at resource-constrained mobile devices. The device-edge co-inference framework provides a promising solution by splitting a neural network at a mobile device and an edge computing server. In order to balance the on-device computation and the communication overhead, the splitting point needs to be carefully picked, while the intermediate feature needs to be compressed before transmission. Existing studies decoupled the design of model splitting, feature compression, and communication, which may lead to excessive resource consumption of the mobile device. In this paper, we introduce an end-to-end architecture, named BottleNet++, that consists of an encoder, a non-trainable channel layer, and a decoder for more efficient feature compression and transmission. The encoder and decoder essentially implement joint source-channel coding via lightweight convolutional neural networks (CNNs), while explicitly considering the effect of channel noise. By exploiting the strong sparsity and the fault-tolerant property of the intermediate feature in deep neural network (DNNs), BottleNet++ achieves a much higher compression ratio than existing methods. Compared with merely transmitting intermediate data without feature compression, BottleNet++ achieves up to 64\u00d7 bandwidth reduction over the additive white Gaussian noise channel and up to 256\u00d7 bit compression ratio in the binary erasure channel, with less than 2% reduction in accuracy of classification.",
    "publication_date": "2019-10-31",
    "venue": "",
    "year": 2019,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "b0d6c77dcc5d0640f44edc769d1017c31d338122",
    "title": "An End-to-end Approach for Handling Unknown Slot Values in Dialogue State Tracking",
    "abstract": "We highlight a practical yet rarely discussed problem in dialogue state tracking (DST), namely handling unknown slot values. Previous approaches generally assume predefined candidate lists and thus are not designed to output unknown values, especially when the spoken language understanding (SLU) module is absent as in many end-to-end (E2E) systems. We describe in this paper an E2E architecture based on the pointer network (PtrNet) that can effectively extract unknown slot values while still obtains state-of-the-art accuracy on the standard DSTC2 benchmark. We also provide extensive empirical evidence to show that tracking unknown values can be challenging and our approach can bring significant improvement with the help of an effective feature dropout technique.",
    "publication_date": "2018-05-01",
    "venue": "",
    "year": 2018,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "328e5747ecb9ff33a7a085574fbfcf854386f0c5",
    "title": "Deep Joint Source-Channel Coding for CSI Feedback: An End-to-End Approach",
    "abstract": "The increased throughput brought by MIMO technology relies on the knowledge of channel state information (CSI) acquired in the base station (BS). To make the CSI feedback overhead affordable for the evolution of MIMO technology (e.g., massive MIMO and ultra-massive MIMO), deep learning (DL) is introduced to deal with the CSI compression task. In traditional communication systems, the compressed CSI bits is treated equally and expected to be transmitted accurately over the noisy channel. While the errors occur due to the limited bandwidth or low signal-to-noise ratios (SNRs), the reconstruction performance of the CSI degrades drastically. As a branch of semantic communications, deep joint source-channel coding (DJSCC) scheme performs better than the separate source-channel coding (SSCC) scheme\u2014the cornerstone of traditional communication systems\u2014in the limited bandwidth and low SNRs. In this paper, we propose a DJSCC based framework for the CSI feedback task. In particular, the proposed method can simultaneously learn from the CSI source and the wireless channel. Instead of truncating CSI via Fourier transform in the delay domain in existing methods, we apply non-linear transform networks to compress the CSI. Furthermore, we adopt an SNR adaption mechanism to deal with wireless channel variations. The extensive experiments demonstrate the validity, adaptability, and generality of the proposed framework.",
    "publication_date": "2022-03-30",
    "venue": "",
    "year": 2022,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "9a0f792933c77a223078d9b413a89ecf22e770ed",
    "title": "Deep Coded Aperture Design: An End-to-End Approach for Computational Imaging Tasks",
    "abstract": "Covering from photography to depth and spectral estimation, diverse computational imaging (CI) applications benefit from the versatile modulation of coded apertures (CAs). The lightwave fields as space, time, or spectral can be modulated to obtain projected encoded information at the sensor that is then decoded by efficient methods, such as the modern deep learning decoders. Although the CA can be fabricated to produce an analog modulation, a binary CA is preferred since more straightforward calibration, higher speed, and lower storage are achieved. As the performance of the decoder mainly depends on the structure of the CA, several works optimize the CA ensembles by customizing regularizers for a particular application without considering the critical physical constraints of the CAs. This work presents an end-to-end (E2E) deep learning-based optimization of CAs for CI tasks. The CA design method aims to cover a wide range of CI problems, easily changing the loss function of the deep approach. The designed loss function includes regularizers to fulfill the widely used sensing requirements of the CI applications. Mainly, the regularizers can be selected to optimize the transmittance, the compression ratio, and the correlation among measurements. At the same time, a binary CA solution is encouraged, and the performance of the CI task is maximized in applications such as restoration, classification, and semantic segmentation.",
    "publication_date": "2021-05-07",
    "venue": "",
    "year": 2021,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e",
    "title": "End-to-End Object Detection with Transformers",
    "abstract": "We present a new method that views object detection as a direct set prediction problem. Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like a non-maximum suppression procedure or anchor generation that explicitly encode our prior knowledge about the task. The main ingredients of the new framework, called DEtection TRansformer or DETR, are a set-based global loss that forces unique predictions via bipartite matching, and a transformer encoder-decoder architecture. Given a fixed small set of learned object queries, DETR reasons about the relations of the objects and the global image context to directly output the final set of predictions in parallel. The new model is conceptually simple and does not require a specialized library, unlike many other modern detectors. DETR demonstrates accuracy and run-time performance on par with the well-established and highly-optimized Faster RCNN baseline on the challenging COCO object detection dataset. Moreover, DETR can be easily generalized to produce panoptic segmentation in a unified manner. We show that it significantly outperforms competitive baselines. Training code and pretrained models are available at this https URL.",
    "publication_date": "2020-05-26",
    "venue": "",
    "year": 2020,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "a3af5c7c9beaf4b92fbe7e8f1720cef566539e05",
    "title": "eHoloNet: a learning-based end-to-end approach for in-line digital holographic reconstruction.",
    "abstract": "It is well known that in-line digital holography (DH) makes use of the full pixel count in forming the holographic imaging. But it usually requires phase-shifting or phase retrieval techniques to remove the zero-order and twin-image terms, resulting in the so-called two-step reconstruction process, i.e., phase recovery and focusing. Here, we propose a one-step end-to-end learning-based method for in-line holography reconstruction, namely, the eHoloNet, which can reconstruct the object wavefront directly from a single-shot in-line digital hologram. In addition, the proposed learning-based DH technique has strong robustness to the change of optical path difference between reference beam and object light and does not require the reference beam to be a plane or spherical wave.",
    "publication_date": "2018-08-20",
    "venue": "",
    "year": 2018,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "260f98c2bfe271d1ad4ffdc7c5cc38f414d3ba70",
    "title": "Sight to Sound: An End-to-End Approach for Visual Piano Transcription",
    "abstract": "Automatic music transcription has primarily focused on transcribing audio to a symbolic music representation (e.g. MIDI or sheet music). However, audio-only approaches often struggle with polyphonic instruments and background noise. In contrast, visual information (e.g. a video of an instrument being played) does not have such ambiguities. In this work, we address the problem of transcribing piano music from visual data alone. We propose an end-to-end deep learning framework that learns to automatically predict note onset events given a video of a person playing the piano. From this, we are able to transcribe the played music in the form of MIDI data. We find that our approach is surprisingly effective in a variety of complex situations, particularly those in which music transcription from audio alone is impossible. We also show that combining audio and video data can improve the transcription obtained from each modality alone.",
    "publication_date": "2020-05-01",
    "venue": "",
    "year": 2020,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "17961de1c23e66242f2cece49b98a08011b137f2",
    "title": "An end-to-end approach to segmentation in medical images with CNN and posterior-CRF",
    "abstract": null,
    "publication_date": "2021-11-01",
    "venue": "",
    "year": 2021,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "0e410a7baeae7f1c8676a6c72898650d1f144ba5",
    "title": "An end-to-end approach to host mobility",
    "abstract": null,
    "publication_date": "2000-08-01",
    "venue": "",
    "year": 2000,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "564f30f2f09e495ca99ad299a4d7c1f251cf8868",
    "title": "SciPred: An end to end approach to classify predatory journals",
    "abstract": "In today\u2019s ruthless academic world, researchers are constantly under pressure to publish work. This has led to significant growth in the number of predatory publishers. With a questionable peer-review process, these publishing houses charge high processing fees in exchange for publishing articles. Given the heterogeneity in academia, identifying such articles is a herculean task. While conventional approaches use metadata of articles, recently an attempt has also been made to use the text itself to filter out such articles. We propose an end-to-end neural network-based pipeline to classify predatory journals. We use a higher dimensional SciBERT model and fine-tune it to the dataset. We also augment the dataset by data from other similar journals.",
    "publication_date": "2022-01-08",
    "venue": "",
    "year": 2022,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "4f2fcc343920a647e6056d6cefa119da7f115048",
    "title": "On end-to-end approach for slice isolation in 5G networks. Fundamental challenges",
    "abstract": "There are several reports and white papers which attempt to precise 5G architectural requirements presenting them from different points of view, including techno-socio-economic impacts and technological constraints. Most of them deal with network slicing aspects as a central point, often strengthening slices with slice isolation. The goal of this paper is to present and examine the isolation capabilities and selected approaches for its realization in network slicing context. As the 5G architecture is still evolving, the specification of isolated slices operation and management brings new requirements that need to be addressed, especially in a context of End-to-End (E2E) security. Thus, an outline of recent trends in slice isolation and a set of challenges are proposed, which (if properly addressed) could be a step to E2E user's security based on slices isolation.",
    "publication_date": "2017-09-24",
    "venue": "",
    "year": 2017,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504",
    "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection",
    "abstract": "DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR, whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10$\\times$ less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach. Code shall be released.",
    "publication_date": "2020-10-08",
    "venue": "",
    "year": 2020,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "2d6130f043e69849fc0443bb489c5d21f933eddd",
    "title": "Deep Recurrent Convolutional Networks for Video-based Person Re-identification: An End-to-End Approach",
    "abstract": "In this paper, we present an end-to-end approach to simultaneously learn spatio-temporal features and corresponding similarity metric for video-based person re-identification. Given the video sequence of a person, features from each frame that are extracted from all levels of a deep convolutional network can preserve a higher spatial resolution from which we can model finer motion patterns. These low-level visual percepts are leveraged into a variant of recurrent model to characterize the temporal variation between time-steps. Features from all time-steps are then summarized using temporal pooling to produce an overall feature representation for the complete sequence. The deep convolutional network, recurrent layer, and the temporal pooling are jointly trained to extract comparable hidden-unit representations from input pair of time series to compute their corresponding similarity value. The proposed framework combines time series modeling and metric learning to jointly learn relevant features and a good similarity measure between time sequences of person. \nExperiments demonstrate that our approach achieves the state-of-the-art performance for video-based person re-identification on iLIDS-VID and PRID 2011, the two primary public datasets for this purpose.",
    "publication_date": "2016-06-06",
    "venue": "",
    "year": 2016,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "c0640f756e018e19f79e18406bbccd5d664c0027",
    "title": "An End-to-End Approach to Self-Folding Origami Structures",
    "abstract": "This paper presents an end-to-end approach to automate the design and fabrication process for self-folding origami structures. Self-folding origami structures are robotic sheets composed of rigid tiles and joint actuators. When they are exposed to heat, each joint folds into a preprogrammed angle. Those folding motions transform themselves into a structure, which can be used as body of 3-D origami robots, including walkers, analog circuits, rotational actuators, and microcell grippers. Given a 3-D model, the design algorithm automatically generates a layout printing design of the sheet form of the structure. The geometric information, such as the fold angles and the folding sequences, is embedded in the sheet design. When the sheet is printed and baked in an oven, the sheet self-folds into the given 3-D model. We discuss, first,\u00a0the design algorithm generating multiple-step self-folding sheet designs, second,\u00a0verification of the algorithm running in <inline-formula><tex-math notation=\"LaTeX\">$O(n^2)$</tex-math> </inline-formula> time, where <inline-formula><tex-math notation=\"LaTeX\">$n$</tex-math></inline-formula> is the number of the vertices, third,\u00a0implementation of the algorithm, and finally, experimental results, several self-folded 3-D structures with up to 55 faces and two sequential folding steps.",
    "publication_date": "2018-12-01",
    "venue": "",
    "year": 2018,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "ebb09a4419d7d04e172f0f1a4642b2feeb44e7bd",
    "title": "A nearly end-to-end deep learning approach to fault diagnosis of wind turbine gearboxes under nonstationary conditions",
    "abstract": null,
    "publication_date": "2023-03-01",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "46d4a2b7ccf38b80b09574cf17544ff2297a8fbf",
    "title": "An End-to-End Steel Surface Defect Detection Approach via Fusing Multiple Hierarchical Features",
    "abstract": "A complete defect detection task aims to achieve the specific class and precise location of each defect in an image, which makes it still challenging for applying this task in practice. The defect detection is a composite task of classification and location, leading to related methods is often hard to take into account the accuracy of both. The implementation of defect detection depends on a special detection data set that contains expensive manual annotations. In this paper, we proposed a novel defect detection system based on deep learning and focused on a practical industrial application: steel plate defect inspection. In order to achieve strong classification ability, this system employs a baseline convolution neural network (CNN) to generate feature maps at each stage, and then the proposed multilevel feature fusion network (MFN) combines multiple hierarchical features into one feature, which can include more location details of defects. Based on these multilevel features, a region proposal network (RPN) is adopted to generate regions of interest (ROIs). For each ROI, a detector, consisting of a classifier and a bounding box regressor, produces the final detection results. Finally, we set up a defect detection data set NEU-DET for training and evaluating our method. On the NEU-DET, our method achieves 74.8/82.3 mAP with baseline networks ResNet34/50 by using 300 proposals. In addition, by using only 50 proposals, our method can detect at 20 ft/s on a single GPU and reach 92% of the above performance, hence the potential for real-time detection.",
    "publication_date": "2020-04-01",
    "venue": "",
    "year": 2020,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "a9bf89cabf405108a08f438f1512023c8dab97ce",
    "title": "End-to-End Approach for Structuring Radiology Reports",
    "abstract": null,
    "publication_date": "2020-06-16",
    "venue": "",
    "year": 2020,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "8f00539b1627a832623af2e9a6f63cdc18ed264d",
    "title": "Exploration of English speech translation recognition based on the LSTM RNN algorithm",
    "abstract": null,
    "publication_date": "2023-03-23",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "decc9fb2eb659b0dab180a7d2c3254f91515ea6b",
    "title": "LSTM-Based Machine Translation for Madurese-Indonesian",
    "abstract": null,
    "publication_date": "2023-09-15",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "a1d99f01fc243de3c31169bd90e0812486afccd0",
    "title": "Exploring LSTM and CNN Architectures for Sign Language Translation",
    "abstract": "Our study explores the application of deep learning models, specifically LSTM (Long Short-Term Memory) and CNN (Convolutional Neural Network), in the realm of sign language translation to address communication barriers faced by individuals with hearing disabilities. Using a dedicated dataset comprising ten frequently used American Sign Language words, we rigorously compare the performance of LSTM and CNN models, measuring precision and recall metrics. The LSTM model achieves a perfect accuracy score of 1, while the CNN model demonstrates a commendable accuracy of 0.9826. These results highlight the potential of these deep learning architectures to facilitate more inclusive and accessible communication avenues in sign language, bridging the communication divide.",
    "publication_date": "2023-10-26",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "f0f970c6c30c4ea0c3c4847e29ae9cdc3839c3ef",
    "title": "Comparative Analysis of LSTM, GRU and Transformer Models for German to English Language Translation",
    "abstract": "Natural Language Processing (NLP) encompasses a broad range of techniques and methodologies for processing and understanding human language. One of the most important NLP applications that has experienced significant advancements and has gained immense importance over the years is Neural Machine Translation. Research on German-to-English language machine translation has remained a prominent area of research within the field of Natural Language Processing and Deep. This paper presents an in-depth analysis of three significant models that are used for Neural Machine Translation namely Recurrent Neural Network with Long Short-Term Memory, Recurrent Neural Network with Gated Recurrent Unit, and the Transformer. For the implementation of each model, a large data corpus of 221,534 sentence pairs is used. Two evaluation metrics are employed to assess the performance of models i.e., the BLEU Score and the ROUGE Score. BLEU-4 Score of 0.386, 0.402, and 0.482 is obtained for RNN+LSTM, RNN+GRU, and Transformer model respectively. Precision, Recall, and F1 Score of ROUGE Score are studied which points to similar results as that Learning of the BLEU Score. Both the evaluation metrics suggest that the transformer model outperforms both variants of RNN. The study also paves the way for further investigation in this area by offering important information about how each model is implemented and the outcomes it produces.",
    "publication_date": "2023-08-25",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "dfb6f3992e2f283ad3011d28ea3889c828438e35",
    "title": "A Hybrid Optimization Approach for Neural Machine Translation Using LSTM+RNN with MFO for Under Resource Language (Telugu)",
    "abstract": "NMT (Neural Machine Translation) is an innovative approach in the field of machine translation, in contrast to SMT (statistical machine translation) and\u00a0Rule-based techniques which has resulted annotable improvements. This is because NMT is able to overcome many of the shortcomings that are inherent in the traditional approaches. The Development of NMT has grown tremendously in the recent years but NMT performance remain under optimal when applied to low resource language pairs like Telugu, Tamil and Hindi. In this work a proposedmethod fortranslating pairs (Telugu to English) is attempted, an optimal approach which enhancesthe accuracy and execution time period.A hybrid method approach utilizing Long short-term memory (LSTM) and traditional Recurrent Neural Network (RNN) are used for testing and training of the dataset. In the event of long-range dependencies, LSTM will generate more accurate results than a standard RNN would endure and the hybrid technique enhances the performance of LSTM. LSTM is used during the encoding and RNN is used in decoding phases of NMT. Moth Flame Optimization (MFO) is utilized in the proposed system for the purpose of providing the encoder and decoder model with the best ideal points for training the data.",
    "publication_date": "2023-09-01",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "69853d672d85b2fb054cee29a15728cf0d2e0c31",
    "title": "Technology of Ukrainian-English Machine Translation Based on Recursive Neural Network as LSTM",
    "abstract": null,
    "publication_date": null,
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "0208bb08efd3398dc1c920655eed2785918d3517",
    "title": "Translation of English Language into Urdu Language Using LSTM Model",
    "abstract": null,
    "publication_date": null,
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "43349bb937c22006af9a00db7b8d8374f89e674b",
    "title": "Indian Sign Language (ISL) Recognition And Translation using Mediapipe and LSTM",
    "abstract": "A person having hearing-impairment is always difficult to communicate with. Without a doubt, sign language has become the finest alternative and a very powerful tool for those who have difficulty speaking or hearing to communicate their opinions and emotions to others. It makes the process of integrating them into society easier and more convenient. The signs usually get jumbled and incomprehensible for someone who has never studied sign language or perceives it in another language. The goal is to develop a method that can enable two-way communication between hearing-impaired persons and others and to break down the communication barrier among those who don\u2019t comprehend sign language and persons with impairments. The objective of this research is to demonstrate and create a method for understanding Indian sign language that combines MediaPipe for hand landmark extraction, LSTM for gesture training and recognition, and also captures either English or Hindi audio through the microphone and recognize it using Google Speech API or convert entered text into their relevant Indian sign language videos.",
    "publication_date": "2023-07-14",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "6fed62a99506a35f7968b74cee707b4d86e9947a",
    "title": "Investigation Of Data Augmentation Techniques For Bi-LSTM Based Direct Speech To Speech Translation",
    "abstract": "Direct speech-to-speech translation (DS2ST) system translates the speech in the source language directly to the speech in the target language. It has been shown in the literature that deep learning systems trained using parallel datasets have given a good translation of the speech. However, getting large datasets to train deep learning networks for DS2ST tasks extensively is not easy. Also, the parallel data might not capture the variabilities like session, gender, speaker, and domain variation that might be present in the real-world dataset. In this work, we explore the data-augmentation techniques such that the pool of the training data can be increased and the DS2ST task can be generalized for all the variations. This work uses noise injection, speed perturbation, pitch perturbation, and vocal tract modification-based data-augmentation approaches as an initial attempt. From the experimental results, it has been found that these augmentation approaches improve the performance of the DS2ST system when compared with the clean/original data. Mel-cepstral distortion (MCD) and intelligibility score (IS) are used as metrics to compare the translated speech with the target language speech. Among the augmentation approaches explored, speed perturbation provides the best improvement of 6.125 in terms of MCD. Vocal tract modification improves the performance of the speaker variability in the dataset. This study shows the robustness of the DS2ST system trained on augmented data.",
    "publication_date": "2023-02-23",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "2519f1cf287b7b7a8301986be31861d16438dc46",
    "title": "ECBTNet: English-Foreign Chinese intelligent translation via multi-subspace attention and hyperbolic tangent LSTM",
    "abstract": null,
    "publication_date": "2023-06-18",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "c92397ca262750f2192e810f144acb8d4792e29d",
    "title": "LSTM-Based Attentional Embedding for English Machine Translation",
    "abstract": "In order to reduce the workload of manual grading and improve the efficiency of grading, a computerized intelligent grading system for English translation based on natural language processing is designed. An attention-embedded LSTM English machine translation model is proposed. Firstly, according to the characteristics of the standard LSTM network model that uses fixed dimensional vectors to represent words in the encoding stage, an English machine translation model based on LSTM attention embedding is established; the structure level of the English translation scoring system is constructed. A linguistic model of the English translation scoring system is established, and the probability distribution of a particular sentence sequence or word sequence of the translated text is statistically calculated using the model. The results show that the English machine translation model based on LSTM attention embedding proposed in this study can enhance the representation of the source language contextual information and improve the performance of the English machine translation model and the quality of the translation compared with the English machine translation models constructed by existing neural network structures, such as standard LSTM models, RNN models, and GRU-Attention translation models.",
    "publication_date": "2022-03-16",
    "venue": "",
    "year": 2022,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "eafa6d3f83ec945b30ad4ea75925e2799a75eaf3",
    "title": "Neural Machine Translation of Spanish-English Food Recipes Using LSTM",
    "abstract": "Nowadays, food is one of the things that has been globalized, and everyone from different parts of the world has been able to cook food from other countries through existing online recipes. Based on that, this study developed a translation formula using a neural machine translation (NMT). NMT is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder\u2013decoders. Our experiment led to novel insights and practical advice for building and extending NMT with the applied long short-term memory (LSTM) method to 47 bilingual food recipes between Spanish-English and English-Spanish. LSTM is one of the best machine learning methods for translating languages because it can retain memories for an extended period concurrently, grasp complicated connections between data, and provides highly useful information in deciding translation outcomes. The evaluation for this neural machine translation is to use BLEU. The comparing results show that the translation of recipes from Spanish-English has a better BLEU value of 0.998426 than English-Spanish with a data-sharing of 70%:30% during epoch 1000. Researchers can convert the country's popular cuisine recipes into another language for further research, allowing it to become more widely recognized abroad.",
    "publication_date": "2022-06-28",
    "venue": "",
    "year": 2022,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "3ead0b8a8984dfe327547652074e80421204a2e7",
    "title": "Application of LSTM Neural Network Technology Embedded in English Intelligent Translation",
    "abstract": "With the rapid development of computer technology, the loss of long-distance information in the transmission process is a prominent problem faced by English machine translation. The self-attention mechanism is combined with convolutional neural network (CNN) and long-term and short-term memory network (LSTM). An English intelligent translation model based on LSTM-SA is proposed, and the performance of this model is compared with other deep neural network models. The study adds SA to the LSTM neural network model and constructs the English translation model of LSTM-SA attention embedding. Compared with other deep learning algorithms such as 3RNN and GRU, the LSTM-SA neural network algorithm has faster convergence speed and lower loss value, and the loss value is finally stable at about 8.6. Under the three values of adaptability, the accuracy of LSTM-SA neural network structure is higher than that of LSTM, and when the adaptability is 1, the accuracy of LSTM-SA neural network improved the fastest, with an accuracy of nearly 20%. Compared with other deep learning algorithms, the LSTM-SA neural network algorithm has a better translation level map under the three hidden layers. The proposed LSTM-SA model can better carry out English intelligent translation, enhance the representation of source language context information, and improve the performance and quality of English machine translation model.",
    "publication_date": "2022-09-27",
    "venue": "",
    "year": 2022,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "c6850869aa5e78a107c378d2e8bfa39633158c0c",
    "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation",
    "abstract": "Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT's use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google's Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units (\"wordpieces\") for both input and output. This method provides a good balance between the flexibility of \"character\"-delimited models and the efficiency of \"word\"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to Google's phrase-based production system.",
    "publication_date": "2016-09-26",
    "venue": "",
    "year": 2016,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "dba08d04e351a9c7d344abca96da696965460e77",
    "title": "Evaluating Text Quality of GPT Engine Davinci-003 and GPT Engine Davinci Generation Using BLEU Score",
    "abstract": "The improvement of text generation based on language models has witnessed significant progress in the field of natural language processing with the use of Transformer-based language models, such as GPT (Generative Pre-trained Transformer). In this study, we conduct an evaluation of text quality using the BLEU (Bilingual Evaluation Understudy) score for two prominent GPT engines: Davinci-003 and Davinci. We generated questions and answers related to Python from internet sources as input data. The BLEU score comparison revealed that Davinci-003 achieved a higher score of 0.035, while Davinci attained a score of 0.021. Additionally, for the response times, with Davinci demonstrating an average response time of 4.20 seconds, while Davinci-003 exhibited a slightly longer average response time of 6.59 seconds. The decision of whether to use Davinci-003 or Davinci for chatbot development should be made based on the specific project requirements. If prioritizing text quality is paramount, Davinci-003 emerges as the superior choice due to its higher BLEU score. However, if faster response times are of greater importance, Davinci may be the more suitable option. Ultimately, the selection should align with the unique needs and objectives of the chatbot development project.",
    "publication_date": "2023-12-10",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "9b43728e887891de89b6a4ab8c265694a016430b",
    "title": "Low-Resource Neural Machine Translation Improvement Using Source-Side Monolingual Data",
    "abstract": "Despite the many proposals to solve the neural machine translation (NMT) problem of low-resource languages, it continues to be difficult. The issue becomes even more complicated when few resources cover only a single domain. In this paper, we discuss the applicability of a source-side monolingual dataset of low-resource languages to improve the NMT system for such languages. In our experiments, we used Wolaytta\u2013English translation as a low-resource language. We discuss the use of self-learning and fine-tuning approaches to improve the NMT system for Wolaytta\u2013English translation using both authentic and synthetic datasets. The self-learning approach showed +2.7 and +2.4 BLEU score improvements for Wolaytta\u2013English and English\u2013Wolaytta translations, respectively, over the best-performing baseline model. Further fine-tuning the best-performing self-learning model showed +1.2 and +0.6 BLEU score improvements for Wolaytta\u2013English and English\u2013Wolaytta translations, respectively. We reflect on our contributions and plan for the future of this difficult field of study.",
    "publication_date": "2023-01-16",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "4b2937658f8d7f21b1c521e2224373976cf4ac15",
    "title": "A STUDY OF DATA AUGMENTATION AND ACCURACY IMPROVEMENT IN MACHINE TRANSLATION FOR VIETNAMESE SIGN LANGUAGE",
    "abstract": "Sign languages are independent languages of deaf communities. The translation from normal languages (i.e., Vietnamese Language - VL) as long as other sign languages to Vietnamese sign language (VSL) is a meaningful task that breaks down communication barriers and improves the quality of life for the deaf community. In this paper, we experimented with and proposed several methods for building and improving models for the VL to VSL translation task. We presented a data augmentation method to improve the performance of our neural machine translation models. Using an initial dataset of 10k bilingual sentence pairs, we were able to obtain a new dataset of 60k sentence pairs with a perplexity score no more than 1.5 times that of the original dataset. Experiments on the original dataset showed that rule-based models achieved the highest BLEU score of 68.02 among the translation models. However, with the augmented dataset, the Transformer model achieved the best performance with a BLEU score of 89.23, which is significantly better than that of other conventional approach methods.",
    "publication_date": "2023-06-12",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "8d9f03acf139e45c6acb5d2a4a71227453dda3ca",
    "title": "Improvement of attention modules for image captioning using pixel-wise semantic information",
    "abstract": "Although an attention mechanism is reasonable for generating image captions, how to obtain ideal image regions within the mechanism is a problem in practice due to the difficulty of its calculation between image and text data. In order to improve the attention modules for image captioning, we propose an algorithm for handling a pixel-wise semantic information, which is obtained as the outputs of semantic segmentation. The proposed method puts the pixel-wise semantic information into the attention modules for image captioning together with input text data and image features. We conducted evaluation experiments and confirmed that our method could obtain more reasonable weighted image features and better image captions with a BLEU-4 score of 0.306 than its original attention model with a BLEU-4 score of 0.243.",
    "publication_date": "2022-10-12",
    "venue": "",
    "year": 2022,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "1c71771c701aadfd72c5866170a9f5d71464bb88",
    "title": "Unified Language Model Pre-training for Natural Language Understanding and Generation",
    "abstract": "This paper presents a new Unified pre-trained Language Model (UniLM) that can be fine-tuned for both natural language understanding and generation tasks. The model is pre-trained using three types of language modeling tasks: unidirectional, bidirectional, and sequence-to-sequence prediction. The unified modeling is achieved by employing a shared Transformer network and utilizing specific self-attention masks to control what context the prediction conditions on. UniLM compares favorably with BERT on the GLUE benchmark, and the SQuAD 2.0 and CoQA question answering tasks. Moreover, UniLM achieves new state-of-the-art results on five natural language generation datasets, including improving the CNN/DailyMail abstractive summarization ROUGE-L to 40.51 (2.04 absolute improvement), the Gigaword abstractive summarization ROUGE-L to 35.75 (0.86 absolute improvement), the CoQA generative question answering F1 score to 82.5 (37.1 absolute improvement), the SQuAD question generation BLEU-4 to 22.12 (3.75 absolute improvement), and the DSTC7 document-grounded dialog response generation NIST-4 to 2.67 (human performance is 2.65). The code and pre-trained models are available at this https URL.",
    "publication_date": "2019-05-08",
    "venue": "",
    "year": 2019,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "828aad53223d29e1bf760116e9651a1237ae8710",
    "title": "Machine Translation with Large Language Models: Prompting, Few-shot Learning, and Fine-tuning with QLoRA",
    "abstract": "While large language models have made remarkable advancements in natural language generation, their potential in machine translation, especially when fine-tuned, remains under-explored. In our study, we conduct comprehensive experiments, evaluating 15 publicly available language models on machine translation tasks. We compare the performance across three methodologies: zero-shot prompting, few-shot learning, and fine-tuning. Central to our approach is the use of QLoRA, an efficient fine-tuning method. On French-English, QLoRA fine-tuning outperforms both few-shot learning and models trained from scratch. This superiority is highlighted in both sentence-level and document-level translations, with a significant BLEU score improvement of 28.93 over the prompting method. Impressively, with QLoRA, the enhanced performance is achieved by fine-tuning a mere 0.77% of the model\u2019s parameters.",
    "publication_date": null,
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "ba0128d5a93868a4d32318e1eac552270b112021",
    "title": "gaHealth: An English\u2013Irish Bilingual Corpus of Health Data",
    "abstract": "Machine Translation is a mature technology for many high-resource language pairs. However in the context of low-resource languages, there is a paucity of parallel data datasets available for developing translation models. Furthermore, the development of datasets for low-resource languages often focuses on simply creating the largest possible dataset for generic translation. The benefits and development of smaller in-domain datasets can easily be overlooked. To assess the merits of using in-domain data, a dataset for the specific domain of health was developed for the low-resource English to Irish language pair. Our study outlines the process used in developing the corpus and empirically demonstrates the benefits of using an in-domain dataset for the health domain. In the context of translating health-related data, models developed using the gaHealth corpus demonstrated a maximum BLEU score improvement of 22.2 points (40%) when compared with top performing models from the LoResMT2021 Shared Task. Furthermore, we define linguistic guidelines for developing gaHealth, the first bilingual corpus of health data for the Irish language, which we hope will be of use to other creators of low-resource data sets. gaHealth is now freely available online and is ready to be explored for further research.",
    "publication_date": "2024-03-06",
    "venue": "",
    "year": 2024,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "bb1f496771d5ef641c9baf42f16900c09ecadb55",
    "title": "Re-evaluating the Role of Bleu in Machine Translation Research",
    "abstract": null,
    "publication_date": "2006-04-01",
    "venue": "",
    "year": 2006,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "1f5e1a036b24b9dd34c006ba3bb61119624f4fdb",
    "title": "A Comprehensive Study of GPT-4V's Multimodal Capabilities in Medical Imaging",
    "abstract": "This paper presents a comprehensive evaluation of GPT-4V's capabilities across diverse medical imaging tasks, including Radiology Report Generation, Medical Visual Question Answering (VQA), and Visual Grounding. While prior efforts have explored GPT-4V's performance in medical imaging, to the best of our knowledge, our study represents the first quantitative evaluation on publicly available benchmarks. Our findings highlight GPT-4V's potential in generating descriptive reports for chest X-ray images, particularly when guided by well-structured prompts. However, its performance on the MIMIC-CXR dataset benchmark reveals areas for improvement in certain evaluation metrics, such as CIDEr. In the domain of Medical VQA, GPT-4V demonstrates proficiency in distinguishing between question types but falls short of prevailing benchmarks in terms of accuracy. Furthermore, our analysis finds the limitations of conventional evaluation metrics like the BLEU score, advocating for the development of more semantically robust assessment methods. In the field of Visual Grounding, GPT-4V exhibits preliminary promise in recognizing bounding boxes, but its precision is lacking, especially in identifying specific medical organs and signs. Our evaluation underscores the significant potential of GPT-4V in the medical imaging domain, while also emphasizing the need for targeted refinements to fully unlock its capabilities.",
    "publication_date": "2023-10-31",
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "9360390b02b9a09ece9a2486055b17e18dc5d3f6",
    "title": "Automatic Code Documentation Generation Using GPT-3",
    "abstract": "Source code documentation is an important artifact for efficient software development. Code documentation could greatly benefit from automation since manual documentation is often labouring, resource and time-intensive. In this paper, we employed Codex for automatic code documentation creation. Codex is a GPT-3 based model pre-trained on both natural and programming languages. We find that Codex outperforms existing techniques even with basic settings like one-shot learning (i.e., providing only one example for training). Codex achieves an overall BLEU score of 20.6 for six different programming languages (11.2% improvement over earlier state-of-the-art techniques). Thus, Codex shows promise and warrants in-depth future studies for automatic code documentation generation to support diverse development tasks.",
    "publication_date": "2022-09-06",
    "venue": "",
    "year": 2022,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "afc70f73d67e62a81f169d288d15861569b7545d",
    "title": "The Improvement of Machine Translation Quality with Help of Structural Analysis and Formal Methods-Based Text Processing",
    "abstract": null,
    "publication_date": null,
    "venue": "",
    "year": 2019,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "5a61757c0e8584ebfda121362a12d0d20ca72eb0",
    "title": "Context-Aware Machine Translation with Source Coreference Explanation",
    "abstract": "Abstract Despite significant improvements in enhancing the quality of translation, context-aware machine translation (MT) models underperform in many cases. One of the main reasons is that they fail to utilize the correct features from context when the context is too long or their models are overly complex. This can lead to the explain-away effect, wherein the models only consider features easier to explain predictions, resulting in inaccurate translations. To address this issue, we propose a model that explains the decisions made for translation by predicting coreference features in the input. We construct a model for input coreference by exploiting contextual features from both the input and translation output representations on top of an existing MT model. We evaluate and analyze our method in the WMT document-level translation task of English-German dataset, the English-Russian dataset, and the multilingual TED talk dataset, demonstrating an improvement of over 1.0 BLEU score when compared with other context-aware models.",
    "publication_date": "2024-04-30",
    "venue": "",
    "year": 2024,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "c3be49ce093afc31cc177d7450d9eefc72447220",
    "title": "Fine Tuning Language Models: A Tale of Two Low-Resource Languages",
    "abstract": "A parallel corpus is an invaluable resource for machine translation. However, creating one is a challenging and time-consuming task. In the Philippines, where 185 languages are spoken, most have abundant text, but annotated data is scarce. Bikol is one of the major languages of the Philippines, yet there have been only a few studies on this language. This study outlines the process of developing a parallel corpus of Bikol and Filipino texts curated from biblical text and Wikipedia articles, as well as translated Bikol songs from various sources. The corpus underwent refinement through manual phrase alignment and translation. Subsequently, T5 and mT5 transformer models were fine-tuned with the parallel corpus and were evaluated using the BLEU metric. A notable improvement in BLEU score was noted following fine-tuning, with an increase of 49.48 in Bik-Fil and 56.07 in Fil-Bik translation. Additionally, human evaluators comprehensively assessed the fine-tuned model's results using Multidimensional Quality Metrics and Scalar Quality Metrics error taxonomies. The fine-tuned models were made publicly accessible through Hugging Face. This study represents a significant stride in advancing machine translation tools for Bikol and Filipino languages.",
    "publication_date": "2024-07-01",
    "venue": "",
    "year": 2024,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "2b87c9c7b04d2e3fe49081e9728b96ccca6329cd",
    "title": "Improvement of English-Hindi machine translation using ConceptNet",
    "abstract": null,
    "publication_date": "2017-10-01",
    "venue": "",
    "year": 2017,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "d12a4ae8f89570d6c5b5d30921c5a7eab1473120",
    "title": "Subset Retrieval Nearest Neighbor Machine Translation",
    "abstract": "k-nearest-neighbor machine translation (kNN-MT) (Khandelwal et al., 2021) boosts the translation performance of trained neural machine translation (NMT) models by incorporating example-search into the decoding algorithm. However, decoding is seriously time-consuming, i.e., roughly 100 to 1,000 times slower than standard NMT, because neighbor tokens are retrieved from all target tokens of parallel data in each timestep. In this paper, we propose \u201cSubset kNN-MT\u201d, which improves the decoding speed of kNN-MT by two methods: (1) retrieving neighbor target tokens from a subset that is the set of neighbor sentences of the input sentence, not from all sentences, and (2) efficient distance computation technique that is suitable for subset neighbor search using a look-up table. Our proposed method achieved a speed-up of up to 132.2 times and an improvement in BLEU score of up to 1.6 compared with kNN-MT in the WMT\u201919 De-En translation task and the domain adaptation tasks in De-En and En-Ja.",
    "publication_date": null,
    "venue": "",
    "year": 2023,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "14f593d7e866d68f78fd84a283e2c751bfa2f667",
    "title": "A Case Study on Filtering for End-to-End Speech Translation",
    "abstract": "It is relatively easy to mine a large parallel corpus for any machine learning task, such as speech-to-text or speech-to-speech translation. Although these mined corpora are large in volume, their quality is questionable. This work shows that the simplest filtering technique can trim down these big, noisy datasets to a more manageable, clean dataset. We also show that using this clean dataset can improve the model's performance, as in the case of the multilingual-to-English Speech Translation (ST) model, where, on average, we obtain a 4.65 BLEU score improvement.",
    "publication_date": "2024-02-02",
    "venue": "",
    "year": 2024,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  },
  {
    "paper_id": "1dbda6b89e7dd966c95c7805f6ea2cafb937cf09",
    "title": "Multilingual Neural Machine Translation with Integrated Language Adapters",
    "abstract": "In response to the issue of multilingual interference in machine translation of minority languages in China, this study proposes an innovative solution based on the Transformer model. The strategy integrates adapter technology by incorporating a small-parameter adapter module on the main model, introducing highly adaptive external components tailored to each language pair to alleviate multilingual interference without altering the main model structure. Experimental results demonstrate the effectiveness of this approach in multilingual translation tasks involving Mongolian, Tibetan, Uyghur, and Chinese. Compared to traditional multilingual baseline models, this method achieves a significant improvement with an average BLEU score increase of up to 1.34 in many-to-one translation scenarios and 0.7 in one-to-many translation scenarios. This work not only provides strong support for addressing multilingual interference in machine translation of minority languages in China but also opens up new avenues and methods for multilingual translation research in other language pairs.",
    "publication_date": "2024-05-10",
    "venue": "",
    "year": 2024,
    "citation_count": 0,
    "authors": "",
    "novel": null,
    "cited_paper": false
  }
]